{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "from geopy import geocoders\n",
    "\n",
    "# Import API key\n",
    "from api_keys import api_key\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "from citipy import citipy\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of each week number\n",
    "weeks = list(range(1,18))\n",
    "# Api Url\n",
    "base_url = \"http://api.fantasy.nfl.com/v1/players/stats?statType=weekStats&season=2018&week={}&form=json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe to contain all the api data\n",
    "temp_final_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes an api call for each week's data and appends it to main dataframe\n",
    "for week in weeks:\n",
    "    target_url = base_url.format(week)\n",
    "    temp = requests.get(target_url).json()['players']\n",
    "    temp_df = pd.DataFrame(temp)\n",
    "    temp_df = temp_df.drop(columns = 'stats')\n",
    "    temp_df['week'] = week\n",
    "    temp_final_df = temp_final_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_final_df[temp_final_df['week'] == 1]\n",
    "team_names = temp_final_df.teamAbbr.unique()\n",
    "team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('2018_Schedule_City.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['away_abrev'] = data['Away'].str[0:4]\n",
    "data['home_abrev'] = data['Home'].str[0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_abrev = []\n",
    "\n",
    "for awy in data['away_abrev']:\n",
    "    away_abrev.append(process.extract(awy,team_names)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_abrev = []\n",
    "\n",
    "for hme in data['home_abrev']:\n",
    "    home_abrev.append(process.extract(hme,team_names)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['away_abrev'] = away_abrev\n",
    "data['home_abrev'] = home_abrev\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "date_str2 = '6/6/18'\n",
    "date_dt2 = datetime.strptime(date_str2, '%m/%d/%y')\n",
    "date_dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Philadelphia, Philadelphia County, Pennsylvania, USA'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_list = data['City'].tolist()\n",
    "city_weather = {}\n",
    "loc = geolocator.geocode(city_list[0])\n",
    "loc.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philadelphia, Philadelphia County, Pennsylvania, USA\n",
      "Philadelphia, Philadelphia County, Pennsylvania, USA\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='myapplication')\n",
    "location = geolocator.geocode(data['City'][0])\n",
    "print(location.address)\n",
    "print(geolocator.geocode(data['City'][0]).address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for city in city_list:\n",
    "    loc = geolocator.geocode(city)\n",
    "    city_weather[city] = geolocator.geocode(loc.address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url used to access the openweathermap api \n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "# Url used to actually access the api data using the provided api key\n",
    "query_url = f\"{url}appid={api_key}&units=imperial&q=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(query_url + location.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url used to access the openweathermap api \n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "# Url used to actually access the api data using the provided api key\n",
    "query_url = f\"{url}appid={api_key}&units=imperial&q=\"\n",
    "\n",
    "# Counter used to count the amount of records being called from openweathermap's api\n",
    "rec_count = 0\n",
    "# Empty list to store the each city's weather data\n",
    "city_data = []\n",
    "\n",
    "print(\"Beginning Data Retrieval\")    \n",
    "print(\"-----------------------------\")\n",
    "# Loop through the list of cities and perform a request for data on each\n",
    "for city in cities:\n",
    "    response = requests.get(query_url + city)\n",
    "    \n",
    "    # If statement used to determine wether the pull was successful and add that to the city_data list\n",
    "    if str(response) == \"<Response [200]>\":\n",
    "        rec_count +=1\n",
    "        print(f\"Processing Record {rec_count} of Set 1 | {city}\")\n",
    "        city_data.append(response.json())\n",
    "    \n",
    "    # Prints if there is no data on that city and leaves out the city name\n",
    "    else:\n",
    "        print(\"City not found. Skipping...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
